1.add PATH variable
2../bin/hive
   if set the HIVE_HOME, hive command will use the configuration files of HIVE_HOME
   if you want to use specific conf, then you should run:
    hive --config configdir


2.install mysql-server
2.1 foracom.mysql.jdbc.driverql-connector-java-5.1.28.jar
  2.1.1 install libmysql-java
  2.1.2 copy mysql-connector-java-5.1.28.jar to HIVE_HOME/lib
2.2 mysql 
  3.1 mysql -uroot -p
  3.1 create database hivemeta;
      CREATE USER 'hive'@'localhost' IDENTIFIED BY 'hivepass';
  3.2 grant all on hivemeta.* to hive@'%' identified by 'hivepass';
  3.3 grant all on hivemeta.* to hive@' localhost.localdomain' identified by 'hivepass';
  3.4  grant all on hivemeta.* to hive@' localhost' identified by 'hivepass';
  3.5 flush privileges;
  
4.use default
  1) hive>
  2) create table testtb1(name string, age int) row format delimited FIELDS TERMINATED BY ' ';
  3) load data local inpath 'test.data' overwrite into table testtb1;
  4)
  select * from testtb1;
  or hive -e 'select * from testtb1'

5.使用metastore
5.1 启动hiveserver：hive --servece hiveserver2 启动在10000端口
5.2 启动metastore：hive --service metastore 启动在9083端口
5.3 使用beeline连接：
   beeline
   this will start a hive server at port 10000, then connect use beeline with jdbc:
  beeline
  !connect jdbc:hive2://localhost:10000 (username 回车; passwd 回车)


5.error:
  Caused by: java.net.URISyntaxException: Relative path in absolute URI: ${system:java.io.tmpdir%7D/$%7Bsystem:user.name%7D
  modify hive-site.xml:
	  <name>hive.exec.scratchdir</name>
	  <value>/tmp/hive-${user.name}</value>

	  <name>hive.exec.local.scratchdir</name>
	  <value>/tmp/${user.name}</value>

	  <name>hive.downloaded.resources.dir</name>
	  <value>/tmp/${user.name}_resources</value>

	  <name>hive.scratch.dir.permission</name>
	  <value>733</value>

6.other user uses hive
  error:
 java.lang.RuntimeException(org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=hadoop-user2, access=EXECUTE, inode="tmp":hadoop-user1:supergroup:rw-rw-rw-) 

 hadoop fs -chmod -R 700 /tmp/
  

7.create external table if not exist etb1(id int, name string) row format delimited fields terminated by ' ' location '/';
8.create external table if not exist etb1(name string) partitioned by (id) row format delimited fields terminated by ' ' location '/';
   set mapreduce.job.queuename=markert;
   /**********************************************/
   set hive.exec.compress.intermediate=true;
   set mapred.map.output.compression.codec=org.apache.hadoop.io.compress.***;
   /**********************************************/
   set hive.exec.compress.output=true;
   set mapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec;
   /**********************************************/
   insert overwrite local directory '/home/liyong/software/output' select * from testtb1;
